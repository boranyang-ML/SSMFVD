{"cells":[{"cell_type":"markdown","source":["Original code authors: Jindong Wang and others (with github link https://github.com/jindongwang/transferlearning).\n","\n","Modified by Boran Yang"],"metadata":{"id":"8yTx7dUa1XhZ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"32n7TNa8PdHN"},"outputs":[],"source":["import os\n","import warnings"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1WruVOCTyHqw"},"outputs":[],"source":["# PWMFD dataset (source domain)\n","\n","# switch to the path where the dataset is stored\n","%cd /content/drive/MyDrive/dataset_images/\n","# copy the dataset (.zip) to the /content path\n","!cp PWMFD_jpg_class.zip /content\n","# switch to content directory\n","%cd /content\n","# unzip dataset zip file\n","!unzip PWMFD_jpg_class.zip -d '/content/dataset'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-XNkCrQkyH7M"},"outputs":[],"source":["# target domain (choose one dataset only)\n","\n","# kaggle dataset\n","# %cd /content/drive/MyDrive/dataset_images/\n","# !cp kaggle_jpg_class_TVT.zip /content\n","# %cd /content\n","# !unzip kaggle_jpg_class_TVT.zip -d '/content/dataset'\n","\n","# SSMFVD dataset\n","%cd /content/drive/MyDrive/dataset_images/\n","!cp SSMFVD_class_TVT.zip /content\n","%cd /content\n","!unzip SSMFVD_class_TVT.zip -d '/content/dataset'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"67cGltxSPj4B","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667743737770,"user_tz":-660,"elapsed":142,"user":{"displayName":"Boran Yang","userId":"06995448423478005580"}},"outputId":"21e3107a-2e3a-4532-a042-31630d217112"},"outputs":[{"output_type":"stream","name":"stdout","text":["Sun Nov  6 14:08:56 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   47C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TF-HUp4dPj6y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667743742568,"user_tz":-660,"elapsed":4803,"user":{"displayName":"Boran Yang","userId":"06995448423478005580"}},"outputId":"0023eb84-87b1-4dce-f157-a4a158c671a9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting configargparse\n","  Downloading ConfigArgParse-1.5.3-py3-none-any.whl (20 kB)\n","Installing collected packages: configargparse\n","Successfully installed configargparse-1.5.3\n"]}],"source":["!pip install configargparse"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CZUcV_g7Pj9Q"},"outputs":[],"source":["import sys\n","# due to the limitation of Google drive, please replace your directory of code here\n","sys.path.append('/content/drive/MyDrive/TrainingStage1')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TbNwHrm1Pj_k"},"outputs":[],"source":["import configargparse\n","import data_loader\n","import os\n","import torch\n","import models\n","import utils\n","from utils import str2bool\n","import numpy as np\n","import random"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fq7MjEEqPkDe"},"outputs":[],"source":["def get_parser():\n","    \"\"\"Get default arguments.\"\"\"\n","    parser = configargparse.ArgumentParser(\n","        description=\"Transfer learning config parser\",\n","        config_file_parser_class=configargparse.YAMLConfigFileParser,\n","        formatter_class=configargparse.ArgumentDefaultsHelpFormatter,\n","    )\n","    # general configuration\n","    parser.add(\"--config\", is_config_file=True, help=\"config file path\")\n","    parser.add(\"--seed\", type=int, default=0)\n","    parser.add_argument('--num_workers', type=int, default=0)\n","    \n","    # network related\n","    parser.add_argument('--backbone', type=str, default='resnet50')\n","    parser.add_argument('--use_bottleneck', type=str2bool, default=False)\n","\n","    # data loading related (the path to the datasets)\n","    parser.add_argument('--data_dir', type=str, default=\"/content/dataset\")\n","    parser.add_argument('--src_domain', type=str, default=\"PWMFD_jpg_class\")\n","    # \"kaggle_jpg_class_TVT/kaggle_jpg_train\"  or  \"SSMFVD_class_TVT/SSMFVD_class_train\"\n","    parser.add_argument('--tgt_domain_train', type=str, default=\"SSMFVD_class_TVT/SSMFVD_class_train\")\n","    # \"kaggle_jpg_class_TVT/kaggle_jpg_valid\"  or  \"SSMFVD_class_TVT/SSMFVD_class_valid\"\n","    parser.add_argument('--tgt_domain_valid', type=str, default=\"SSMFVD_class_TVT/SSMFVD_class_valid\")\n","    \n","    # training related\n","    parser.add_argument('--batch_size', type=int, default=64)\n","    parser.add_argument('--n_epoch', type=int, default=50)\n","    parser.add_argument('--early_stop', type=int, default=0, help=\"Early stopping\")\n","    parser.add_argument('--epoch_based_training', type=str2bool, default=False, help=\"Epoch-based training / Iteration-based training\")\n","    parser.add_argument(\"--n_iter_per_epoch\", type=int, default=30, help=\"Used in Iteration-based training\")\n","\n","    # optimizer related\n","    parser.add_argument('--lr', type=float, default=0.01)\n","    parser.add_argument('--momentum', type=float, default=0.9)\n","    parser.add_argument('--weight_decay', type=float, default=5e-4)\n","\n","    # learning rate scheduler related\n","    parser.add_argument('--lr_gamma', type=float, default=0.0003)\n","    parser.add_argument('--lr_decay', type=float, default=0.75)\n","    parser.add_argument('--lr_scheduler', type=str2bool, default=True)\n","\n","    # transfer related\n","    parser.add_argument('--transfer_loss_weight', type=float, default=10)\n","    parser.add_argument('--transfer_loss', type=str, default='lmmd')\n","    return parser"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NYgMc8PDPkFa"},"outputs":[],"source":["def set_random_seed(seed=0):\n","    # seed setting\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0Okqpz9YP_aF"},"outputs":[],"source":["def load_data(args):\n","    '''\n","    src_domain, tgt_domain data to load\n","    '''\n","    folder_src = os.path.join(args.data_dir, args.src_domain)\n","    folder_tgt_train = os.path.join(args.data_dir, args.tgt_domain_train)\n","    folder_tgt_valid = os.path.join(args.data_dir, args.tgt_domain_valid)\n","\n","    source_loader, n_class = data_loader.load_data(\n","        folder_src, args.batch_size, infinite_data_loader=not args.epoch_based_training, train=True, num_workers=args.num_workers)\n","    target_train_loader, _ = data_loader.load_data(\n","        folder_tgt_train, args.batch_size, infinite_data_loader=not args.epoch_based_training, train=True, num_workers=args.num_workers)\n","    target_test_loader, _ = data_loader.load_data(\n","        folder_tgt_valid, args.batch_size, infinite_data_loader=False, train=False, num_workers=args.num_workers)\n","    return source_loader, target_train_loader, target_test_loader, n_class"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MxlS1WmnP_Xu"},"outputs":[],"source":["def get_model(args):\n","    model = models.TransferNet(\n","        args.n_class, transfer_loss=args.transfer_loss, base_net=args.backbone, max_iter=args.max_iter, use_bottleneck=args.use_bottleneck).to(args.device)\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XCCy-OQZP_U6"},"outputs":[],"source":["def get_optimizer(model, args):\n","    initial_lr = args.lr if not args.lr_scheduler else 1.0\n","    params = model.get_parameters(initial_lr=initial_lr)\n","    optimizer = torch.optim.SGD(params, lr=args.lr, momentum=args.momentum, weight_decay=args.weight_decay, nesterov=False)\n","    return optimizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EclYfB5YP_SP"},"outputs":[],"source":["def get_scheduler(optimizer, args):\n","    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lambda x:  args.lr * (1. + args.lr_gamma * float(x)) ** (-args.lr_decay))\n","    return scheduler"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1sfIIqwyP_P5"},"outputs":[],"source":["def train(source_loader, target_train_loader, target_test_loader, model, optimizer, lr_scheduler, args):\n","    len_source_loader = len(source_loader)\n","    len_target_loader = len(target_train_loader)\n","    n_batch = min(len_source_loader, len_target_loader)\n","    if n_batch == 0:\n","        n_batch = args.n_iter_per_epoch \n","    \n","    iter_source, iter_target = iter(source_loader), iter(target_train_loader)\n","\n","    best_acc = 0\n","    stop = 0\n","    log = []\n","    for e in range(1, args.n_epoch+1):\n","        model.train()\n","        train_loss_clf = utils.AverageMeter()\n","        train_loss_transfer = utils.AverageMeter()\n","        train_loss_total = utils.AverageMeter()\n","        model.epoch_based_processing(n_batch)\n","        \n","        if max(len_target_loader, len_source_loader) != 0:\n","            iter_source, iter_target = iter(source_loader), iter(target_train_loader)\n","        \n","        criterion = torch.nn.CrossEntropyLoss()\n","        for _ in range(n_batch):\n","            data_source, label_source = next(iter_source) \n","            data_target, label_target = next(iter_target)  \n","            data_source, label_source = data_source.to(args.device), label_source.to(args.device)\n","            data_target, label_target = data_target.to(args.device), label_target.to(args.device)\n","\n","            clf_loss, transfer_loss = model(data_source, data_target, label_source, label_target) \n","\n","            loss = clf_loss + args.transfer_loss_weight * transfer_loss\n","            \n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            if lr_scheduler:\n","                lr_scheduler.step()\n","\n","            train_loss_clf.update(clf_loss.item())\n","            train_loss_transfer.update(transfer_loss.item())\n","            train_loss_total.update(loss.item())\n","            \n","        log.append([train_loss_clf.avg, train_loss_transfer.avg, train_loss_total.avg])\n","        \n","        info = 'Epoch: [{:2d}/{}], cls_loss: {:.4f}, transfer_loss: {:.4f}, total_Loss: {:.4f}'.format(\n","                        e, args.n_epoch, train_loss_clf.avg, train_loss_transfer.avg, train_loss_total.avg)\n","        # Test\n","        stop += 1\n","        test_acc, test_loss = test(model, target_test_loader, args)\n","        # print(\"model:\", model)\n","        # print(\"model state_dict:\", model.state_dict())\n","        # print(\"args:\", args)\n","        save_files = {'model': model.state_dict()}\n","        torch.save(save_files, \"/content/drive/MyDrive/TrainingStage1/save_weights/T1-model-{}.pth\".format(e))\n","        info += ', test_loss {:4f}, test_acc: {:.4f}'.format(test_loss, test_acc)\n","        np_log = np.array(log, dtype=float)\n","        np.savetxt('train_log.csv', np_log, delimiter=',', fmt='%.6f')\n","        if best_acc < test_acc:\n","            best_acc = test_acc\n","            stop = 0\n","        if args.early_stop > 0 and stop >= args.early_stop:\n","            print(info)\n","            break\n","        print(info)\n","    print('Transfer result: {:.4f}'.format(best_acc))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Os7RZtNPP_Mh"},"outputs":[],"source":["def test(model, target_test_loader, args):\n","    model.eval()\n","    test_loss = utils.AverageMeter()\n","    correct = 0\n","    criterion = torch.nn.CrossEntropyLoss()\n","    len_target_dataset = len(target_test_loader.dataset)\n","    with torch.no_grad():\n","        for data, target in target_test_loader:\n","            data, target = data.to(args.device), target.to(args.device)\n","            s_output = model.predict(data)\n","            loss = criterion(s_output, target)\n","            test_loss.update(loss.item())\n","            pred = torch.max(s_output, 1)[1]\n","            correct += torch.sum(pred == target)\n","    acc = 100. * correct / len_target_dataset\n","    return acc, test_loss.avg"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l0rW5iKMQNnF"},"outputs":[],"source":["def main():\n","    parser = get_parser()\n","    # set the parser\n","    args = parser.parse_args(args = [\"--config\",\"/content/drive/MyDrive/TrainingStage1/DSAN.yaml\"]) # config file path\n","    setattr(args, \"device\", torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n","    print(args)\n","    set_random_seed(args.seed)\n","    source_loader, target_train_loader, target_test_loader, n_class = load_data(args) # \n","    setattr(args, \"n_class\", n_class)\n","    if args.epoch_based_training:\n","        setattr(args, \"max_iter\", args.n_epoch * min(len(source_loader), len(target_train_loader)))\n","    else:\n","        setattr(args, \"max_iter\", args.n_epoch * args.n_iter_per_epoch)\n","    model = get_model(args)\n","    optimizer = get_optimizer(model, args)\n","    \n","    if args.lr_scheduler:\n","        scheduler = get_scheduler(optimizer, args)\n","    else:\n","        scheduler = None\n","    train(source_loader, target_train_loader, target_test_loader, model, optimizer, scheduler, args)\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A25OmOyoQNjV"},"outputs":[],"source":["if __name__ == \"__main__\":\n","  main()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pM1rcGi4P_BN"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"mount_file_id":"17RpUVdPOOsTE4wlh0HfP654LNGUryZ9m","authorship_tag":"ABX9TyNsZ7eEkqx4ytEk5+nabhs6"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}